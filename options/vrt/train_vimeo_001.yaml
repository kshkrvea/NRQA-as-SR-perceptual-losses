# cutblur off
task: 001_train_vrt_vimeo_7frames
model: vrt
gpu_ids: [1]
dist: true
find_unused_parameters: false
use_static_graph: true
weights_scale: 2
scale: 2
n_channels: 3

# finetune on realvsr pretrained 002_finetune_vrt_realvsr_7frames model (all layers) w/o cutblur
path: 
    root: ../mnt/calypso/checkpoints

datasets: 
  train: 
    name: train_dataset
    dataroot_gt: ../mnt/calypso/datasets/vimeo90k/vimeo90k_train_GT.lmdb
    dataroot_lq: ../mnt/calypso/datasets/vimeo90k/vimeo90k_train_LR7frames.lmdb
    io_backend: 
      type: lmdb
    num_frame: 7
    gt_size: 128
    interval_list: [1]
    random_reverse: true
    use_hflip: true
    use_rot: true
    pad_sequence: false
    scale: 2
    dataloader_shuffle: true
    dataloader_num_workers: 12
    dataloader_batch_size: 1
    
  test: 
    name: test_dataset
    dataroot_gt: ../mnt/calypso/datasets/vimeo90k/vimeo90k_test_GT.lmdb
    dataroot_lq: ../mnt/calypso/datasets/vimeo90k/vimeo90k_test_LR7frames.lmdb
    cache_data: true
    io_backend: 
      type: lmdb
    num_frame: 7
    gt_size: 128
    interval_list: [1]
    random_reverse: false
    use_hflip: false
    use_rot: false
    pad_sequence: false
    scale: 2
    dataloader_shuffle: false
    dataloader_num_workers: 12
    

netG: 
  net_type: vrt
  spynet_path: model_zoo/vrt/spynet_sintel_final-3d2a1287.pth   # automatical download
  arguments:
    upscale: 2
    img_size: [6,64,64]
    window_size: [6,8,8]
    depths: [8,8,8,8,8,8,8, 4,4,4,4, 4,4]
    indep_reconsts: [11,12]
    embed_dims: [120,120,120,120,120,120,120, 180,180,180,180, 180,180]
    num_heads: [6,6,6,6,6,6,6, 6,6,6,6, 6,6]
    pa_frames: 2
    deformable_groups: 12
    nonblind_denoising: false
    use_checkpoint_attn: false
    use_checkpoint_ffn: false
    no_checkpoint_attn_blocks: []
    no_checkpoint_ffn_blocks: []
  init_type: default
  unfreeze_blocks: 0


train: 
  G_lossfn_types: ['charbonnier']
  G_lossfn_weights: [1]
  G_charbonnier_eps: 1e-9

  E_decay: 0 # Exponential Moving Average for netG: set 0 to disable; default setting 0.999

  G_optimizer_type: adam        # fixed, adam is enough
  G_optimizer_lr: 4e-4            # learning rate
  G_optimizer_betas: [0.9,0.99]
  G_optimizer_wd: 0               # weight decay, default 0
  G_optimizer_clipgrad: null      # unused
  G_optimizer_reuse: true         #

  fix_iter: 35000
  total_iter: 35000  
  fix_keys: ["spynet", "deform"]
  G_scheduler:
    type: CosineCycleAnnealingWarmRestarts
    params:
      start_value: 1e-3
      end_value: 1e-6
      cycle_size: 1000
      start_value_mult: 0.8
      end_value_mult: 1

  G_regularizer_orthstep: null    # unused
  G_regularizer_clipstep: null    # unused

  G_param_strict: false
  E_param_strict: false

  checkpoint_test: 500           # for testing
  checkpoint_save: 500           # for saving model
  checkpoint_print: 10          # for print

